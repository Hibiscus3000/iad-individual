{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T14:25:00.313481412Z",
     "start_time": "2023-12-24T14:25:00.312922151Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_dataset_name = 'train2023.csv'\n",
    "testing_dataset_name = 'test2023.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec97b01c4a4981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T14:25:00.889789878Z",
     "start_time": "2023-12-24T14:25:00.313243292Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(os.path.join('data', training_dataset_name), sep=';', header=None)\n",
    "test_df = pd.read_csv(os.path.join('data', testing_dataset_name), sep=';', header=None)\n",
    "\n",
    "classes = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d5adb2e0a427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T14:25:00.890747330Z",
     "start_time": "2023-12-24T14:25:00.885169837Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede138860eb526a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T14:25:02.038229585Z",
     "start_time": "2023-12-24T14:25:00.897416696Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "class OutlierTransformer:\n",
    "\n",
    "    def __init__(self, outlier_detector, class_labels):\n",
    "        self._class_labels = class_labels\n",
    "        self._outlier_detector = outlier_detector\n",
    "\n",
    "    def fit_transform(self, X, y, logging_level):\n",
    "        before = X.shape\n",
    "        X_separated_by_class = {i: X[y == i, :] for i in self._class_labels}\n",
    "        X_separated_by_class_cleared = {i:\n",
    "                                            X_separated_by_class[i][\n",
    "                                            self._outlier_detector.fit_predict(X=X_separated_by_class[i]) == 1, :] for i\n",
    "                                        in\n",
    "                                        self._class_labels}\n",
    "        X = np.vstack(list(X_separated_by_class_cleared.values()))\n",
    "        after = X.shape\n",
    "        y = np.hstack([np.full(X_separated_by_class_cleared[i].shape[0], i) for i in self._class_labels])\n",
    "        logging.log(level=logging_level, msg=f'CLEARING OUTLIERS: {before} -> {after}')\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf92b9e7b5e1ab1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T14:25:02.119696350Z",
     "start_time": "2023-12-24T14:25:02.041517493Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "class Scheme:\n",
    "\n",
    "    def __init__(self, pipeline: Pipeline, outlier_detector=None, class_labels=classes, hyperparams_str: str = None):\n",
    "        if outlier_detector is not None:\n",
    "            self._outlier_transformer = OutlierTransformer(outlier_detector=outlier_detector, class_labels=classes)\n",
    "        else:\n",
    "            self._outlier_transformer = None\n",
    "        self._pipeline = pipeline\n",
    "\n",
    "        self.hyperparams = hyperparams_str\n",
    "\n",
    "    def fit(self, X, y, logging_level=logging.INFO):\n",
    "        if self._outlier_transformer is not None:\n",
    "            X, y = self._outlier_transformer.fit_transform(X=X, y=y, logging_level=logging_level)\n",
    "        self._pipeline.fit(X=X, y=y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self._pipeline.predict(X=X)\n",
    "    \n",
    "    def predict_proba(self, X): \n",
    "        return np.max(self._pipeline.predict_proba(X=X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e28abfbc1432dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T14:25:02.285063531Z",
     "start_time": "2023-12-24T14:25:02.084003792Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def tune_hyperparams(schemas, X, y, metric: callable, n_splits: int = 5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    best_scheme = None\n",
    "    best_score = None\n",
    "    for scheme in schemas:\n",
    "        score = 0\n",
    "        logging.debug(scheme.hyperparams)\n",
    "        for train, valid in skf.split(X, y):\n",
    "            scheme.fit(X=X[train], y=y[train], logging_level=logging.DEBUG)\n",
    "            y_predict = scheme.predict(X[valid])\n",
    "            score += metric(y[valid], y_predict)\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            best_scheme = scheme\n",
    "        logging.debug('metric = ' + str(score / n_splits))\n",
    "    return best_scheme, best_score / n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e61109b2dc808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T14:25:02.286732014Z",
     "start_time": "2023-12-24T14:25:02.238980735Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.iloc[:, :-1], train_df.iloc[:, -1]\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = test_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16f2ebe25a373e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T14:25:02.373390597Z",
     "start_time": "2023-12-24T14:25:02.296994788Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "metrics = {\"ACCURACY\": accuracy_score, \"F1\": f1_score, \"PRECISION\": precision_score, \"RECALL\": recall_score,\n",
    "           \"AUC\": roc_auc_score}\n",
    "scorers = {metric_name: make_scorer(metric_callable) for metric_name, metric_callable in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9256424f9b89f4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T14:25:02.410075651Z",
     "start_time": "2023-12-24T14:25:02.317864431Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_iterable(obj):\n",
    "    try:\n",
    "        iter(obj)\n",
    "        return True\n",
    "    except TypeError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f50704e2b6a0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T14:25:02.411169007Z",
     "start_time": "2023-12-24T14:25:02.361661447Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_test(scheme, result_filename: str, hyperparams_metric=accuracy_score):\n",
    "    if is_iterable(scheme):\n",
    "        logging.info('HYPERPARAMS TUNING')\n",
    "        scheme, hyperparams_tuning_metric = tune_hyperparams(schemas=scheme, X=X_train, y=y_train,\n",
    "                                                             metric=accuracy_score)\n",
    "        logging.info('HYPERPARAMS TUNING: ' + scheme.hyperparams + '. METRIC: ' + str(hyperparams_tuning_metric))\n",
    "\n",
    "    logging.info('TRAINING')\n",
    "    scheme.fit(X=X_train, y=y_train)\n",
    "\n",
    "    logging.info('PREDICTING')\n",
    "    y_predict = scheme.predict(X=X_test)\n",
    "    y_predict_proba = scheme.predict_proba(X=X_test)\n",
    "    y_predict_df = pd.DataFrame(data={'class': y_predict, 'certainty': y_predict_proba})\n",
    "    y_predict_df.to_csv(os.path.join('result', result_filename + '.csv'), header=True, index=False, mode='w')\n",
    "\n",
    "    return scheme, y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40dd6a330a3bb78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T14:25:40.235005578Z",
     "start_time": "2023-12-24T14:25:36.793698901Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "schemes_knn = [Scheme(pipeline=Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('feature_selector', SelectPercentile(score_func=mutual_info_classif, percentile=50)),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=n, weights='distance'))\n",
    "]), outlier_detector=LocalOutlierFactor(n_neighbors=n), hyperparams_str=f'number of neighbours = {n}') for n in range(1, 2)]\n",
    "train_and_test(scheme=schemes_knn, result_filename='KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9448f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier \n",
    "\n",
    "schemes_mlp = []\n",
    "for i in range(15, 16):\n",
    "    for j in range(10, 11):\n",
    "        for k in range(5, 6):\n",
    "            schemes_mlp.append(Scheme(pipeline=Pipeline(steps=[\n",
    "                ('scaler', MinMaxScaler()),\n",
    "                ('feature_selector', SelectPercentile(score_func=mutual_info_classif, percentile=50)),\n",
    "                ('classifier', MLPClassifier(\n",
    "                                    hidden_layer_sizes=[50 * i, 50 * j, 50 * k],\n",
    "                                    max_iter=1000,\n",
    "                                ))]), outlier_detector=LocalOutlierFactor(n_neighbors=15), hyperparams_str=f'layers = ({i}, {j}, {k})'))\n",
    "train_and_test(scheme=schemes_mlp, result_filename='MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e4824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "scheme_tree = Scheme(pipeline=Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('feature_selector', SelectPercentile(score_func=mutual_info_classif, percentile=50)),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='entropy', min_samples_split = 0.05, ))\n",
    "]), outlier_detector=IsolationForest(n_jobs=-1))    \n",
    "train_and_test(scheme=scheme_tree, result_filename='Decision tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d5309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scheme_lr = Scheme(\n",
    "    pipeline=Pipeline(\n",
    "        steps=[\n",
    "            (\"scaler\", MinMaxScaler()),\n",
    "            ('feature_selector', SelectPercentile(score_func=mutual_info_classif, percentile=50)),  # normalize each feature independently\n",
    "            (\"classifier\", LogisticRegression()),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "train_and_test(scheme=scheme_lr, result_filename='Logistic regression')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
